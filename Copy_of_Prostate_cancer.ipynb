{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boteny02/prostate_me/blob/main/Copy_of_Prostate_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PSA DATA FOR PROSTATE CANCER PREDICTION"
      ],
      "metadata": {
        "id": "UEXiOc48e0Df"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Necessary libraries"
      ],
      "metadata": {
        "id": "u9TpyiW-ZT69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay # Import ConfusionMatrixDisplay\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "J5BXn1vDAXlg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Dataset From Drive"
      ],
      "metadata": {
        "id": "y9RJwBAUZRpR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_5cQ4Es_3FJ"
      },
      "outputs": [],
      "source": [
        "Path =\"/content/drive/MyDrive/Prostate cancer/extracted Values of Lab Test Results PSA.xlsx\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Qnm-IqWC0lAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(Path)\n",
        "print(df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5Tz3og3xAa85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bBMbIN0OyW-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wg3BhZWgy797"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns\n"
      ],
      "metadata": {
        "id": "YeM70D_mJF1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()\n",
        "df['Age']"
      ],
      "metadata": {
        "id": "wQNS2_vR8Olo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import count\n",
        "# Assuming your DataFrame is named 'df' and the column with string values is 'Test Value'\n",
        "# Replace '>100', '<0.1', etc., with appropriate numerical representations\n",
        "\n",
        "df['Test Value'] = pd.to_numeric(df['Test Value'], errors='coerce')  # Convert to numeric, invalid parsing will be set as NaN\n",
        "xdf=df[df['Test Value']>100]\n",
        "\n",
        "# Now, if you want to replace NaN values with something like the mean:\n",
        "#df['Test Value'].fillna(df['Test Value'].mean(), inplace=True)  # Replace NaN with the column's mean\n",
        "\n",
        "#print(xdf)\n",
        "print(df.head(10))\n"
      ],
      "metadata": {
        "id": "yKPq7hhtCdjg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Test Value'].fillna(df['Test Value'].mean(), inplace=True)  # Replace NaN with the column's mean\n"
      ],
      "metadata": {
        "id": "j9VElwJREbQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select features and target variable\n",
        "X = df.drop(columns=[\"With In Normal\"])  # Assuming \"With In Normal\" is the target\n",
        "y = df[\"With In Normal\"].apply(lambda x: 1 if x == \"Yes\" else 0)  # Convert to binary labels"
      ],
      "metadata": {
        "id": "-ZzqVErHSDiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize numerical features using Min-Max Scaling\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)"
      ],
      "metadata": {
        "id": "vC3TaK0aSHb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split of the Dataset"
      ],
      "metadata": {
        "id": "kUbjaezOZx8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "d148bMxRSwy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define of the base model and meta model"
      ],
      "metadata": {
        "id": "PUST22WKdWVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define base models (Random Forest + XGBoost)\n",
        "base_models = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('xgb', XGBClassifier( eval_metric='logloss', random_state=42))\n",
        "]\n",
        "\n",
        "# Meta-model\n",
        "meta_model = LogisticRegression()"
      ],
      "metadata": {
        "id": "93T4UOWZRHkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Stack Model"
      ],
      "metadata": {
        "id": "ZA6CuR5idgQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Stacking Model\n",
        "stacked_model = StackingClassifier(estimators=base_models, final_estimator=meta_model, cv=10)\n",
        "stacked_model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "t5ghqvf0RqpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of Each Base Model"
      ],
      "metadata": {
        "id": "EDYSWmFzdl0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate each base model separately\n",
        "for name, model in base_models:\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds) # Use preds instead of y_pred\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(f\"Model {name} Accuracy: {acc*100:.2f}%\")\n",
        "    dis = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    dis.plot(cmap=\"Accent\")\n",
        "    #plt.show()"
      ],
      "metadata": {
        "id": "icfjhMWLRvG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: classification report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# ... (Your existing code) ...\n",
        "\n",
        "# Evaluate each base model separately\n",
        "for name, model in base_models:\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    cm = confusion_matrix(y_test, preds)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(f\"Model {name} Accuracy: {acc*100:.2f}%\")\n",
        "    print(classification_report(y_test,preds)) #added classification report\n",
        "    dis = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    dis.plot(cmap=\"Accent\")\n",
        "    #plt.show()\n"
      ],
      "metadata": {
        "id": "NmzKZGLVzgFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation of the Stack Model"
      ],
      "metadata": {
        "id": "rk0pD4STeDfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = stacked_model.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Stacked Ensemble Model Accuracy: {accuracy*100:.2f}%\")"
      ],
      "metadata": {
        "id": "Ly0j2vaMeLmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Display the matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=\"Blues\")"
      ],
      "metadata": {
        "id": "U4-RAW2Ql8YI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: averaging\n",
        "\n",
        "# Calculate the average accuracy of the base models\n",
        "base_model_accuracies = []\n",
        "for name, model in base_models:\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    base_model_accuracies.append(acc)\n",
        "\n",
        "average_accuracy = sum(base_model_accuracies) / len(base_model_accuracies)\n",
        "print(f\"Average accuracy of base models: {average_accuracy*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "qfWSr0t93uL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: majority voting\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def majority_voting(y_pred_rf, y_pred_xgb, y_pred_stacked):\n",
        "  \"\"\"\n",
        "  Performs majority voting among three prediction arrays.\n",
        "\n",
        "  Args:\n",
        "      y_pred_rf: Predictions from the Random Forest model.\n",
        "      y_pred_xgb: Predictions from the XGBoost model.\n",
        "      y_pred_stacked: Predictions from the stacked model.\n",
        "\n",
        "  Returns:\n",
        "      A NumPy array representing the majority vote predictions.\n",
        "  \"\"\"\n",
        "\n",
        "  # Combine predictions into a single array\n",
        "  combined_predictions = np.column_stack((y_pred_rf, y_pred_xgb, y_pred_stacked))\n",
        "\n",
        "  # Perform majority voting\n",
        "  majority_votes = np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=combined_predictions)\n",
        "\n",
        "  return majority_votes\n",
        "\n",
        "\n",
        "# Example usage (assuming you have the predictions from your models):\n",
        "# Replace these with your actual predictions from the trained models\n",
        "y_pred_rf = stacked_model.predict(X_test) #Example only, use actual predictions from rf model\n",
        "y_pred_xgb = stacked_model.predict(X_test) #Example only, use actual predictions from xgb model\n",
        "y_pred_stacked = stacked_model.predict(X_test) #Example only, use actual predictions from stacked model\n",
        "\n",
        "\n",
        "# Perform majority voting\n",
        "majority_predictions = majority_voting(y_pred_rf, y_pred_xgb, y_pred_stacked)\n",
        "\n",
        "# Evaluate the majority voting results\n",
        "accuracy = accuracy_score(y_test, majority_predictions)\n",
        "print(f\"Majority Voting Accuracy: {accuracy*100:.2f}%\")\n",
        "\n",
        "cm = confusion_matrix(y_test, majority_predictions)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=\"Blues\")\n",
        "\n"
      ],
      "metadata": {
        "id": "YvUcXyy935MV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}